{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ckf9HBuk4bah"
   },
   "source": [
    "# Gym environment for a High Contrast Imaging instrument's AO control system.\n",
    "\n",
    "## Attributes:\n",
    "This is a simplified HCI system environment. The dynamics of the environment is based on a Markov Decision Process. The relevant attributes are the \"state\", \"action\", \"reward\".  \n",
    "The state in this case is the WFS recorded phase projected on the DM actuator mode basis. For example, with a 25x25 actuator DM the state is a 25x25 matrix of actuator values.  \n",
    "The action is the additional actuator levels above the flat level calculated by inverting the DM influence matrix. A matrix equal in dimensions to the state vector.  \n",
    "The reward is a single scalar value, which in this case corresponds to the achieved contrast within the dark hole. Specifically, it is the negative log of the contrast. A high reward implies high contrast at the dark hole.\n",
    "\n",
    "## Description:\n",
    "1. The optical system is defined in a class that inherits from OpenAI's gym environment class.\n",
    "2. This class contains 3 main methods - \\_\\_init\\_\\_(...), step(...), reset(...).\n",
    "3. The \\_\\_init\\_\\_(...) method sets up the optical system with the following components in order: a turbulence generator, a demagnifier, a DM, a WFS, a coronagraph, a quasi-static NCPA aberration, and a detector.\n",
    "4. The step(action) function does the following:\n",
    "* The DM is updated with the actuator values specified in the \"action\".\n",
    "* The wavefront is propagated through the entire optical path, i.e. the WFS optical path as well as the science optical path.\n",
    "* The WFS measurement is read out. The state variable for WFS measurement is updated.\n",
    "* The instantaneous focal plane image is calculated.\n",
    "* A reward is calculated using the metric function on the focal plane image, and is used to update the reward variable.\n",
    "* The timestep is incremented by 1, and the turbulence generator is evolved accordingly.\n",
    "5. A reinforcement learning algorithm works in this environment to maximize expected future reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OJMsldF_5U70"
   },
   "source": [
    "### Step 1: Installing hcipy on colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lX6JfIQ35Vjo"
   },
   "outputs": [],
   "source": [
    "!pip uninstall hcipy\n",
    "!rm -rf hcipy\n",
    "!git clone https://github.com/ehpor/hcipy.git\n",
    "!cd hcipy; git pull\n",
    "!cd hcipy; python setup.py install\n",
    "!pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_227Uh2v5wz8"
   },
   "source": [
    "### Step 2: Importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_-ee-0x5Z6_"
   },
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "from hcipy import *\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import os, glob\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4sAMe8k55kL"
   },
   "source": [
    "### Step 3: Defining the HCI testbench class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GUTf4Eqo50Gj"
   },
   "outputs": [],
   "source": [
    "from HCI_TestBench import HCI_TestBench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddm8ZTXH6MwL"
   },
   "source": [
    "### Step 4: Define testbench parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn7ScAI96Hlz"
   },
   "outputs": [],
   "source": [
    "# Create aperture and pupil/focal grids\n",
    "wavelength = 532e-9\n",
    "N = 512\n",
    "D = 10.5e-3\n",
    "pupil_grid = make_pupil_grid(N, D)\n",
    "science_focal_grid = make_focal_grid(8, 20, wavelength/D)\n",
    "aperture = circular_aperture(D)\n",
    "\n",
    "# Telescope parameters\n",
    "Dtel = 1\n",
    "tel_pupil_grid = make_pupil_grid(N, Dtel)\n",
    "tel_aperture = circular_aperture(Dtel)\n",
    "\n",
    "# Create the deformable mirror\n",
    "actuator_grid = make_pupil_grid(12, D*1.1)\n",
    "xinetics_basis = make_xinetics_influence_functions(pupil_grid, 12, D * 1.1 / 12)\n",
    "dm = DeformableMirror(xinetics_basis)\n",
    "num_modes = len(dm.influence_functions)\n",
    "dm.actuators = np.zeros(num_modes)\n",
    "\n",
    "# Atmosphere parameters\n",
    "velocity = 10 #m/s\n",
    "L0 = 40 # outer scale\n",
    "r0 = 0.4 # Fried parameter\n",
    "height = 0 # layer height\n",
    "\n",
    "# Make atmosphere\n",
    "np.random.seed(19900305)\n",
    "layers = []\n",
    "layer = InfiniteAtmosphericLayer(tel_pupil_grid, Cn_squared_from_fried_parameter(r0, 500e-9), L0, velocity, height, stencil_length=2, use_interpolation=True)\n",
    "layers.append(layer)\n",
    "atmosphere = MultiLayerAtmosphere(layers, False)\n",
    "\n",
    "## Create a demagnifier\n",
    "demag = Magnifier(D / Dtel)\n",
    "\n",
    "# Make initial phasescreen\n",
    "wf_tel = Wavefront(tel_aperture(tel_pupil_grid), wavelength)\n",
    "wf_tel.total_power = 100000\n",
    "wf = demag.forward(wf_tel)\n",
    "\n",
    "## Create propagator from pupil to focal plane\n",
    "prop = FraunhoferPropagator(pupil_grid, science_focal_grid)\n",
    "\n",
    "## Get the app coronagraph\n",
    "app_amp = fits.getdata('Square_20_80_20_25_0_2_amp_resampled_512.fits').ravel()\n",
    "app_phase = fits.getdata('Square_20_80_20_25_0_2_phase_resampled_512.fits').ravel()\n",
    "app = Apodizer(app_amp * np.exp(1j * app_phase))\n",
    "\n",
    "## Create detector\n",
    "science_camera = NoiselessDetector()\n",
    "\n",
    "## Generate a diffraction limited image for metrics\n",
    "diff_lim_img = prop(wf).power\n",
    "\n",
    "## Get the unit lambda/D\n",
    "l_D = wavelength / D\n",
    "plot_grid = make_focal_grid(8, 20, 1)\n",
    "\n",
    "## Create a noiseless camera image from the perfectly flat wavefront with coronograph\n",
    "wfdm = dm.forward(wf)\n",
    "wfapp = app.forward(wfdm)\n",
    "imapp = prop(wfapp).power\n",
    "dz_ind = np.where((imapp.grid.x >= (2 * l_D)) &\\\n",
    "                  (imapp.grid.x <= (8 * l_D)) &\\\n",
    "                  (imapp.grid.y >= (-3 * l_D)) &\\\n",
    "                  (imapp.grid.y <= (3 * l_D)))\n",
    "\n",
    "## Create an NCP aberration\n",
    "num_coeffs = 9\n",
    "plaw_index = -1\n",
    "np.random.seed(7)\n",
    "coeffs = ((np.random.rand(num_coeffs) - 0.5) * 2) * (np.arange(num_coeffs, dtype=float) + 1) ** plaw_index\n",
    "coeffs = np.zeros(coeffs.shape)\n",
    "zernike_basis = make_zernike_basis(num_coeffs, D, pupil_grid, 2)\n",
    "ncp_phase = np.dot(zernike_basis.transformation_matrix, coeffs)\n",
    "ncp = Apodizer(np.exp(1j * ncp_phase))\n",
    "\n",
    "# Create an estimate of the NCP aberration for the forward model\n",
    "ncp_field_est = np.exp(1j * np.zeros(app_phase.shape))\n",
    "estimated_coeffs = np.zeros(coeffs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OajqgOZH7aeq",
    "outputId": "f72e7c4e-5caf-43cc-feae-7d3c7a9f188a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float64\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "tb = HCI_TestBench(wf_tel, atmosphere, demag, dm, None, ncp, app, prop, science_camera, dz_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VQea5RJ0LItE"
   },
   "source": [
    "### Step 5: Train the DDPG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Umt8ZL_LSo5"
   },
   "outputs": [],
   "source": [
    "from agent import DDPG\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82riCCgf9LsM"
   },
   "outputs": [],
   "source": [
    "# Start with supervised learning trained model that mimics the identity function\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "trained_model = load_model('identity_function.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_T10NGl_LlVT"
   },
   "outputs": [],
   "source": [
    "# Define all hyperparameters here\n",
    "ACTOR_LR = 5e-5\n",
    "CRITIC_LR = 1e-3\n",
    "RANDOM_SEED = 42\n",
    "MU = 0.0\n",
    "SIGMA = 1.0\n",
    "BUFFER_SIZE = 1e4\n",
    "BATCH_SIZE = 8\n",
    "GAMMA = 0.0\n",
    "TAU = 1e-2\n",
    "N_TIME_STEPS = 1\n",
    "N_LEARN_UPDATES = 1\n",
    "NOISE_SCALER = 0\n",
    "NOISE_DECAY = 0.99\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    DEVICE = \"/GPU:0\"\n",
    "else:\n",
    "    DEVICE = \"/device:CPU:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHrX0V1iM3VK"
   },
   "outputs": [],
   "source": [
    "state_size = (12, 12, 1)\n",
    "action_size = (12, 12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDaqZ_LJMgRx"
   },
   "outputs": [],
   "source": [
    "agent = DDPG(state_size, action_size, ACTOR_LR, CRITIC_LR,\n",
    "             RANDOM_SEED, MU, SIGMA, BUFFER_SIZE, BATCH_SIZE,\n",
    "             GAMMA, TAU, N_TIME_STEPS, N_LEARN_UPDATES, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfeGMvAg9dvk"
   },
   "outputs": [],
   "source": [
    "agent.actor_local.model.set_weights(trained_model.get_weights())\n",
    "agent.actor_target.model.set_weights(trained_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yprFnutRMyny",
    "outputId": "c1967fa7-c0bd-4a4d-bd6e-a06729466f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 84\t Time in ms:10\t Average Score: 2.20"
     ]
    }
   ],
   "source": [
    "def ddpg(n_episodes=1000, print_every=100):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = tb.reset()\n",
    "        agent.reset()\n",
    "        score = 0\n",
    "        t = 0\n",
    "        \n",
    "        while(t < 10): # 10ms per episode\n",
    "            t += 1\n",
    "            action = agent.act(state, NOISE_SCALER)\n",
    "            next_state, reward, done, _ = tb.step(action)\n",
    "            agent.step(t, state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_deque.append(score / t)\n",
    "        scores.append(score / t)\n",
    "        print('\\rEpisode {}\\t Time in ms:{}\\t Average Score: {:.2f}'.format(i_episode, t, np.mean(scores_deque)), end=\"\")\n",
    "        agent.actor_local.model.save('checkpoint_actor.h5')\n",
    "        agent.critic_local.model.save('checkpoint_critic.h5')\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            \n",
    "        if np.mean(scores_deque) >= 8.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_deque)))\n",
    "            agent.actor_local.model.save('checkpoint_actor.h5')\n",
    "            agent.critic_local.model.save('checkpoint_critic.h5')\n",
    "            break\n",
    "            \n",
    "    return scores\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HCI_DRL_2Dstate.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
